{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a47c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "# %%\n",
    "# IMPORTANTE: EJECUTA ESTA CELDA PARA IMPORTAR TUS FUENTES DE DATOS DE KAGGLE,\n",
    "# LUEGO PUEDES ELIMINAR ESTA CELDA SI LO DESEAS.\n",
    "# NOTA: ESTE ENTORNO DE NOTEBOOK ES DIFERENTE AL ENTORNO DE PYTHON DE KAGGLE,\n",
    "# POR LO QUE PODRÍA FALTAR ALGUNA LIBRERÍA USADA EN TU NOTEBOOK.\n",
    "import kagglehub\n",
    "yudhaislamisulistya_plants_type_datasets_path = kagglehub.dataset_download('yudhaislamisulistya/plants-type-datasets')\n",
    "keras_efficientnetv2_keras_efficientnetv2_b0_imagenet_2_path = kagglehub.model_download('keras/efficientnetv2/Keras/efficientnetv2_b0_imagenet/2')\n",
    "\n",
    "print('Importación de fuente de datos completada.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8762811d",
   "metadata": {},
   "source": [
    "## Descripción del dataset: \n",
    "El dataset contiene 30 000 imágenes de plantas, con 1000 imágenes por clase, y una colección diversa de 30 clases de plantas y 7 tipos de plantas, incluyendo cultivos, frutales, plantas industriales, medicinales, frutos secos, tubérculos y hortalizas. Las 30 clases de plantas incluyen especies populares como el plátano, el coco y la piña, así como plantas menos conocidas como el bilimbi y el galanga."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d1bfb3",
   "metadata": {},
   "source": [
    "## Preparación de datos\n",
    "El primer paso incluye:\n",
    "\n",
    "Importación de bibliotecas\n",
    "Creación de conjuntos de datos\n",
    "En la carpeta \"plants-type-datasets\" que se encuentra en la plataforma de kaggle hay 30 000 imágenes de plantas divididas en tres carpetas (entrenamiento, prueba y validación). Para nuestra notebook, las tres carpetas se unirán y dividirán aleatoriamente más adelante. Por lo tanto, al principio habrá pasos adicionales para la preparación de los conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d01f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# keras_cv para el uso del modelo preentrenado\n",
    "import keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e4dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de etiquetas y rutas de imágenes\n",
    "dataset_root = '/kaggle/input/plants-type-datasets/split_ttv_dataset_type_of_plants'\n",
    "labels = []\n",
    "images_path = []\n",
    "\n",
    "# Iterar a través de los subdirectorios (categorías de plantas)\n",
    "for dataset in os.listdir(dataset_root):\n",
    "    for plant_category in os.listdir(os.path.join(dataset_root, dataset)):\n",
    "        if os.path.isdir(os.path.join(dataset_root, dataset, plant_category)):\n",
    "            images = os.listdir(os.path.join(dataset_root, dataset, plant_category))\n",
    "\n",
    "            # Crea un marco de datos con image_path y etiqueta\n",
    "            for image in images:\n",
    "                image_path = os.path.join(dataset_root, dataset, plant_category, image)\n",
    "                images_path.append(image_path)\n",
    "                labels.append(plant_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f010949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificación de la etiqueta y la ruta de la imagen\n",
    "i = random.randint(0, 30000)\n",
    "print(f'number of labels: {len(labels)} and images {len(images_path)}\\n')\n",
    "print('label of random plant: ', labels[i])\n",
    "print('path to random image: ', images_path[i], '\\n')\n",
    "Image(images_path[i])\n",
    "# preparación general de X e y\n",
    "X = images_path\n",
    "y = labels\n",
    "\n",
    "# División del dataset para entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)\n",
    "\n",
    "len(X_train), len(y_train), len(X_val), len(y_val), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359afccb",
   "metadata": {},
   "source": [
    "# Preprocesamiento de imágenes\n",
    "## (conversión de imágenes en tensores)\n",
    "Pasos para convertir imágenes a formato numérico y dividirlas en fragmentos más pequeños (lotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc81fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parámetros para la imagen y el tamaño del lote\n",
    "img_size = 28\n",
    "batch_size = 32 \n",
    "\n",
    "def prepare_image(image_path):\n",
    "    '''\n",
    "    turns an image into a tensor\n",
    "    '''\n",
    "    # leer una imagen\n",
    "    image = tf.io.read_file(image_path)\n",
    "    # convertir una imagen a versión numérica\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # convierte colores de 0-255 a 0-1\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # cambiar el tamaño\n",
    "    image = tf.image.resize(image, size=[img_size, img_size])\n",
    "\n",
    "    return image\n",
    "\n",
    "def get_label_image(image_path, label):\n",
    "    image = prepare_image(image_path)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def create_batches(X, y=None, batch_size=batch_size, test_data=False):\n",
    "    '''\n",
    "    split a dataset to batches\n",
    "    '''\n",
    "    if test_data:\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
    "        data_batch = data.map(get_label_image).batch(batch_size)\n",
    "    else:\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
    "        data = data.shuffle(buffer_size=len(X))\n",
    "        data_batch = data.map(get_label_image).batch(batch_size)\n",
    "\n",
    "    return data_batch\n",
    "\n",
    "# Creación de lotes para todos los conjuntos de datos\n",
    "\n",
    "# Entrenamiento de datos\n",
    "train_data = create_batches(X_train, y_train)\n",
    "\n",
    "# datos de prueba\n",
    "test_data = create_batches(X_test, y_test, test_data=True)\n",
    "\n",
    "# datos de validación\n",
    "val_data = create_batches(X_val, y_val, test_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe26f76",
   "metadata": {},
   "source": [
    "# Creación, entrenamiento y validación del modelo\n",
    "\n",
    "En este capítulo, construiremos y entrenaremos los siguientes modelos:\n",
    "* Modelo preentrenado del repositorio de Kaggle: https://www.kaggle.com/models/keras/efficientnetv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac4794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaración de formas de entrada y salida\n",
    "input_shape = [img_size, img_size, 3]\n",
    "output_shape = len(encoding_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c7e12",
   "metadata": {},
   "source": [
    "## Modelo \n",
    "As a model  we will use one of the earlier trained model from kaggle repository: **EfficientNetV2**\n",
    "\n",
    "https://www.kaggle.com/models/keras/efficientnetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir el modelo\n",
    "model = keras_cv.models.ImageClassifier.from_preset(\n",
    "    \"efficientnetv2_b0_imagenet\",\n",
    "    num_classes=output_shape\n",
    ")\n",
    "\n",
    "# compilar el modelo\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# construir el modelo\n",
    "model.build(input_shape)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# entrenamiento de modelos\n",
    "model.fit(x=train_data,\n",
    "            epochs=5,\n",
    "            validation_data=val_data,\n",
    "            validation_freq=1\n",
    "         )\n",
    "\n",
    "# Guarda model\n",
    "model.save('modelos/aprendiendomachin.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42949c44",
   "metadata": {},
   "source": [
    "## Predicciones (opcional usarlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para codificar etiquetas\n",
    "def pred_labels(prediction_propabilities):\n",
    "\n",
    "    return encoding_labels[np.argmax(prediction_propabilities)]\n",
    "\n",
    "# verificación de modelos en datos de prueba\n",
    "models = [ model]\n",
    "index = random.randint(0, len(y_val))\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    y_pred = model.predict(test_data)\n",
    "    predictions = []\n",
    "    test = []\n",
    "    for i in range(len(y_pred)):\n",
    "        predictions.append(pred_labels(y_pred[i]))\n",
    "        test.append(pred_labels(y_test[i]))\n",
    "\n",
    "    label = pred_labels(y_pred[index])\n",
    "    print(f'Is {pred_labels(y_test[index])} predicted properly? Prediction: {label}. So:  {label==pred_labels(y_test[index])}')\n",
    "    print('Accuracy for the whole test dataset: ', round(accuracy_score(test, predictions), 2), '\\n--- ---\\n')\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Random plant\\'s picture from test dataset which name models tried to predict')\n",
    "Image(X_test[index])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
